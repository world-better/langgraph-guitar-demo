# 2025.07.25 项目进度总结

## 1. 核心瓶颈确认

经过测试，我们一致认为当前仅使用 OpenCV 的 alpha 混合技术无法达到理想的、照片般逼真的贴纸融合效果。这确认了项目的一个核心技术瓶颈。

## 2. 新的技术方案：混合工作流

我们对当前行业内先进的图像生成应用（如 Tattoo.ai）进行了研究，并确定了新的、更强大的技术实现方案：

- **第一阶段 (CV 预处理)**: 继续使用 OpenCV 来处理几何问题。这包括对贴纸进行**透视变换**，并根据变换后的形状生成精确的**位置掩码 (Mask)**。
- **第二阶段 (生成式融合)**: 将预处理好的吉他原图、掩码、以及描述性的文本提示 (Prompt)，一同提交给一个带有 **Inpainting + ControlNet** 功能的**扩散模型 API**。模型将会在掩码限定的区域内进行智能重绘，从而生成与环境光影、纹理完美融合的逼真图像。

## 3. API 平台调研

考虑到自己托管扩散模型的成本和复杂性，我们调研了市面上提供此类功能的 API 平台。

- **结论**: 找到了多个可行的低成本或免费的平台，其中 **Replicate** 因其按秒计费的模式和丰富的 Inpainting + ControlNet 模型库，成为我们搭建 Demo 的首选。

## 4. 下一步计划 (核心任务)

- **集成 API**: 当前的首要任务是**集成 Replicate 的 API**。我们将修改现有的 LangGraph 工作流，在 `apply_sticker_transform_node` 之后，添加一个新的节点来调用该 API，以完成最终的图像生成。
- **暂停非核心功能**: 为了集中精力攻克核心的渲染问题，我们将暂时**搁置**其他高级功能的开发，例如让 AI 自动确定贴纸位置等。当前将使用手动画定的区域坐标进行开发和测试。 